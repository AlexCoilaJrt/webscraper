# ğŸ•·ï¸ Web Scraper 

Un sistema completo de web scraping con anÃ¡lisis inteligente, anÃ¡lisis de sentimientos, sistema de anuncios, chatbot con LLM, gestiÃ³n de usuarios y suscripciones. Extrae artÃ­culos de mÃºltiples periÃ³dicos y los almacena en una base de datos SQLite con interfaz web moderna.

## âš¡ Inicio RÃ¡pido

Â¿Quieres empezar rÃ¡pido? Sigue estos pasos:

```bash
# 1. Clonar el repositorio
git clone https://github.com/AlexCoilaJrt/webscraper.git
cd webscraper

# 2. Configurar backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# 3. Configurar frontend
cd frontend
npm install
cd ..

# 4. Iniciar el sistema
# Terminal 1 - Backend
python api_server.py

# Terminal 2 - Frontend
cd frontend
npm start
```

**Acceder a la aplicaciÃ³n:**
- Frontend: http://localhost:3001
- Backend API: http://localhost:5001

**Credenciales por defecto:**
- Usuario: `admin`
- ContraseÃ±a: `AdminSecure2024!`

> âš ï¸ **Nota**: El sistema funciona sin LLM. Solo el chatbot no funcionarÃ¡ sin configuraciÃ³n adicional. Ver secciÃ³n [Configurar LLM](#4-configurar-llm-opcional---solo-para-chatbot) para habilitar el chatbot.

## ğŸŒŸ Nuevas Funcionalidades

### âœ¨ Sistema de AnÃ¡lisis de Sentimientos
- **AnÃ¡lisis avanzado** de sentimientos (positivo, negativo, neutral) usando VADER y TextBlob
- **DetecciÃ³n de emociones**: enojo, alegrÃ­a, miedo, tristeza, sorpresa, disgusto
- **PolarizaciÃ³n de opiniones**: alta, media, baja
- **EvoluciÃ³n temporal**: grÃ¡ficos de sentimiento a lo largo del tiempo
- **ComparaciÃ³n entre medios**: anÃ¡lisis comparativo de sentimientos por periÃ³dico
- **ComparaciÃ³n con comentarios virales**: anÃ¡lisis de noticias vs comentarios sociales
- **Alertas inteligentes**: notificaciones cuando el sentimiento es muy negativo
- **IntegraciÃ³n con anuncios**: colocaciÃ³n inteligente de anuncios segÃºn sentimiento

### ğŸ’¬ Chatbot Inteligente con LLM
- **Asistente conversacional** integrado con LLM (Ollama/OpenRouter/Groq/Hugging Face)
- **BÃºsqueda inteligente** de artÃ­culos por texto, fecha o tema
- **ResÃºmenes automÃ¡ticos** de noticias
- **Consulta de planes** y lÃ­mites de suscripciÃ³n
- **DetecciÃ³n automÃ¡tica de fechas**: soporta "hoy", "esta semana", "este mes", rangos personalizados
- **Prompts rÃ¡pidos** para consultas comunes
- **ConfiguraciÃ³n flexible**: Ollama (local, gratuito), OpenRouter, Groq, o Hugging Face (API externa)
- **Sistema de fallback inteligente**: Si el LLM configurado falla, el sistema automÃ¡ticamente:
  1. Intenta APIs gratuitas sin key (Together AI, Perplexity, DeepInfra)
  2. Si fallan, intenta el proveedor configurado (Groq, Hugging Face, OpenRouter, Ollama)
  3. Si el proveedor configurado falla, intenta Hugging Face como fallback automÃ¡tico
  4. Si todo falla o hay timeout (8 segundos), usa un sistema de respuestas inteligentes basado en el contexto del portal
- **Siempre funcional**: El chatbot siempre responderÃ¡, incluso si todos los LLMs fallan, usando respuestas contextuales inteligentes

### ğŸ“¢ Sistema de Anuncios (Ads)
- **GestiÃ³n de campaÃ±as publicitarias** completa
- **Anuncios inteligentes** basados en sentimiento del contenido
- **Carrusel de anuncios** en el Dashboard (rotaciÃ³n automÃ¡tica cada 3 segundos)
- **MÃ©tricas y analytics** de rendimiento de anuncios
- **IntegraciÃ³n con sentimientos**: evitar anuncios en contenido muy negativo
- **Sistema de tracking**: clicks, impresiones, conversiones
- **Recomendaciones automÃ¡ticas** de colocaciÃ³n

### ğŸ’­ Comentarios Virales
- **SecciÃ³n de comentarios virales** en el Dashboard
- **Comentarios de usuarios** sobre temas virales
- **Sistema de likes** para comentarios
- **AnÃ¡lisis de sentimiento** automÃ¡tico de comentarios
- **Filtrado por tema** y popularidad
- **IntegraciÃ³n con anÃ¡lisis de sentimientos**

### ğŸ” Sistema de AutenticaciÃ³n y Permisos
- **AutenticaciÃ³n completa** con JWT tokens
- **Sistema de roles**: Admin, Usuario
- **Permisos dinÃ¡micos**: el admin puede otorgar permisos especÃ­ficos a usuarios
- **GestiÃ³n de usuarios** completa desde el panel de admin
- **Control granular** de acceso a funcionalidades
- **Sistema independiente de planes**: permisos no afectan suscripciones

### ğŸ’³ Sistema de Suscripciones
- **Planes de suscripciÃ³n**: Freemium, Premium, Enterprise
- **LÃ­mites por plan**: artÃ­culos, scraping, chat, exportaciÃ³n
- **GestiÃ³n de pagos** (panel admin)
- **CaracterÃ­sticas por plan**:
  - **Freemium**: BÃ¡sico, anÃ¡lisis de sentimientos bÃ¡sico
  - **Premium**: AnÃ¡lisis avanzado, comparaciÃ³n con comentarios, alertas
  - **Enterprise**: Todo lo anterior + integraciÃ³n inteligente de anuncios

### ğŸ“Š AnÃ¡lisis Avanzado
- **Dashboard de anÃ¡lisis completo** con mÃºltiples visualizaciones
- **Tendencias temporales** de contenido
- **AnÃ¡lisis de sentimientos** por periÃ³dico y categorÃ­a
- **Top categorÃ­as y periÃ³dicos** mÃ¡s activos
- **Nube de palabras** con las palabras mÃ¡s frecuentes
- **ComparaciÃ³n de periÃ³dicos** con mÃ©tricas detalladas
- **EstadÃ­sticas detalladas** por medio de comunicaciÃ³n

### ğŸ“± Redes Sociales (Proyecto AcadÃ©mico)
- **Scraping de redes sociales**: Twitter/X, Facebook, Reddit, YouTube
- **AnÃ¡lisis de sentimientos** en posts sociales
- **ClasificaciÃ³n por categorÃ­as** automÃ¡tica
- **Dashboard de redes sociales** con visualizaciones
- **âš ï¸ Solo para fines acadÃ©micos y educativos**

### ğŸ”® Trending Topics Predictor
- **PredicciÃ³n de temas trending** 24-48 horas antes de que se vuelvan virales
- **AnÃ¡lisis de patrones histÃ³ricos** de los Ãºltimos 14 dÃ­as
- **MÃ©tricas de confianza** y potencial viral
- **ExtracciÃ³n automÃ¡tica** de palabras clave relevantes
- **CategorizaciÃ³n automÃ¡tica** (General, TecnologÃ­a, PolÃ­tica, etc.)
- **Dashboard visual** con mÃ©tricas en tiempo real
- **Sistema de lÃ­mites** por plan de suscripciÃ³n

### ğŸ” Competitive Intelligence
- **Monitoreo de competidores** en tiempo real
- **DetecciÃ³n automÃ¡tica** de menciones en artÃ­culos
- **AnÃ¡lisis de sentimiento** de menciones
- **Sistema de alertas** automÃ¡ticas
- **Dashboard de mÃ©tricas** y estadÃ­sticas
- **Sugerencias de IA** para keywords relevantes
- **AnÃ¡lisis de artÃ­culos existentes** sin necesidad de nuevo scraping

## ğŸ“Š EstadÃ­sticas del Proyecto

- **ğŸ“° Total de artÃ­culos extraÃ­dos:** 1,600+
- **ğŸ–¼ï¸ Total de imÃ¡genes descargadas:** 1,500+
- **ğŸ“ˆ Sesiones de scraping:** 100+
- **ğŸ—ï¸ PeriÃ³dicos configurados:** 10
- **ğŸ¤– Sistema de scraping automÃ¡tico:** Activo (cada 5 minutos)
- **ğŸŒ MÃ©todos de scraping:** 5 (AnÃ¡lisis Inteligente, HÃ­brido, Optimizado, Mejorado, Selenium)
- **ğŸ’¾ Base de datos:** SQLite con mÃºltiples tablas especializadas
- **ğŸ”„ Ãšltima actualizaciÃ³n:** Sistema en funcionamiento continuo

## ğŸ—ï¸ PeriÃ³dicos Configurados

### ğŸ“Š Resumen de PeriÃ³dicos

| PeriÃ³dico | RegiÃ³n | CategorÃ­a | Estado | ArtÃ­culos/Max | ImÃ¡genes/Max |
|-----------|--------|-----------|--------|---------------|--------------|
| **El Comercio** | Nacional | General | âœ… Activo | 50 | 1 |
| **El Popular** | Nacional | General | âœ… Activo | 40 | 1 |
| **Diario Sin Fronteras** | Nacional | Regional | âœ… Activo | 35 | 1 |
| **El Peruano** | Nacional | EconomÃ­a | âœ… Activo | 40 | 1 |
| **Peru21** | Nacional | General | âœ… Activo | 40 | 1 |
| **Ojo** | Nacional | General | âœ… Activo | 35 | 1 |
| **Trome** | Nacional | General | âœ… Activo | 35 | 1 |
| **El Mundo** | Extranjero | Internacional | âœ… Activo | 50 | 1 |
| **La Vanguardia** | Extranjero | Internacional | âœ… Activo | 50 | 1 |
| **New York Times** | Extranjero | Internacional | âœ… Activo | 40 | 1 |

## âœ¨ CaracterÃ­sticas Principales

### ğŸ§  AnÃ¡lisis Inteligente
- **DetecciÃ³n automÃ¡tica** del mejor mÃ©todo de scraping
- **AnÃ¡lisis de pÃ¡gina** (JavaScript, SPA, paginaciÃ³n, lazy loading)
- **RecomendaciÃ³n inteligente** con nivel de confianza
- **DetecciÃ³n de idioma** y clasificaciÃ³n regional automÃ¡tica

### ğŸ”„ Scraping AutomÃ¡tico
- **PaginaciÃ³n automÃ¡tica** para extraer todos los artÃ­culos
- **Sistema de cron** configurado para ejecutar cada 5 minutos
- **MÃºltiples mÃ©todos** de scraping (AnÃ¡lisis Inteligente, HÃ­brido, Optimizado, Mejorado, Selenium)
- **Scraping independiente** sin necesidad de servidor API
- **PrevenciÃ³n de duplicados** automÃ¡tica

### ğŸ“Š GestiÃ³n de Datos
- **Base de datos SQLite** para almacenamiento local
- **ExportaciÃ³n a Excel** con formato profesional
- **Filtros avanzados** por periÃ³dico, categorÃ­a, regiÃ³n, fecha
- **BÃºsqueda de texto** en tÃ­tulos y contenido
- **GestiÃ³n de periÃ³dicos** con eliminaciÃ³n selectiva
- **Limpieza masiva** de datos

### ğŸ¨ Interfaz Moderna
- **Frontend React** con Material-UI v7 y TypeScript
- **Dashboard profesional** con estadÃ­sticas en tiempo real
- **GalerÃ­a de imÃ¡genes** con vista previa
- **GrÃ¡ficos interactivos** (ECharts) para anÃ¡lisis de datos
- **Sistema de notificaciones** en tiempo real
- **DiseÃ±o responsivo** y moderno
- **Tema claro/oscuro** configurable

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Backend
- **Python 3.11+**
- **Flask** - Framework web REST API
- **SQLite** - Base de datos principal
- **Selenium** - AutomatizaciÃ³n de navegador
- **BeautifulSoup** - Parsing HTML
- **Requests** - Cliente HTTP
- **Pandas** - ManipulaciÃ³n de datos
- **OpenPyXL** - ExportaciÃ³n Excel
- **SQLAlchemy** - ORM para base de datos
- **VADER Sentiment** - AnÃ¡lisis de sentimientos
- **TextBlob** - AnÃ¡lisis de texto
- **APScheduler** - ProgramaciÃ³n de tareas
- **JWT** - AutenticaciÃ³n

### Frontend
- **React 19** con TypeScript
- **Material-UI v7** - Componentes UI modernos
- **ECharts** - GrÃ¡ficos interactivos avanzados
- **Axios** - Cliente HTTP
- **React Router** - NavegaciÃ³n
- **Date-fns** - ManipulaciÃ³n de fechas
- **XLSX** - ExportaciÃ³n de archivos

### LLM (Opcional)
- **Ollama** - LLM local gratuito (recomendado)
- **OpenRouter** - API de LLM externa (alternativa)

## ğŸ“¦ InstalaciÃ³n

### Prerrequisitos
- **Python 3.11 o superior** - [Descargar Python](https://www.python.org/downloads/)
- **Node.js 16 o superior** - [Descargar Node.js](https://nodejs.org/)
- **npm o yarn** - Viene incluido con Node.js
- **Git** - [Descargar Git](https://git-scm.com/downloads)
- **Chrome o Chromium** - Requerido para Selenium (el sistema descarga ChromeDriver automÃ¡ticamente)
- **Ollama (opcional)** - Solo si quieres usar el chatbot con LLM local

### 1. Clonar el Repositorio
```bash
git clone https://github.com/AlexCoilaJrt/webscraper.git
cd webscraper
```

### 2. Configurar Backend (Python)
```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# En macOS/Linux:
source venv/bin/activate
# En Windows:
# venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

**Nota**: Si tienes problemas con alguna dependencia, intenta actualizar pip:
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 3. Configurar Frontend (React)
```bash
cd frontend
npm install
```

**Nota**: Si tienes problemas con npm, intenta:
```bash
npm cache clean --force
npm install
```

### 4. Configurar Variables de Entorno (Opcional)

El sistema funciona sin configuraciÃ³n adicional, pero puedes personalizar opciones creando un archivo `.env` en la raÃ­z del proyecto:

```bash
# Crear archivo .env (opcional)
touch .env  # En Windows: crear archivo .env manualmente
```

**Variables opcionales para el Chatbot con LLM:**
```env
# OpciÃ³n 1: Ollama (Local, Gratuito)
LLM_PROVIDER=ollama
LLM_MODEL=llama3

# OpciÃ³n 2: OpenRouter (API Externa)
LLM_PROVIDER=openrouter
LLM_MODEL=deepseek/deepseek-chat-v3.1:free
OPENROUTER_API_KEY=sk-or-tu-api-key

# OpciÃ³n 3: Groq (API Externa, RÃ¡pida)
LLM_PROVIDER=groq
LLM_MODEL=mixtral-8x7b-32768
GROQ_API_KEY=tu-groq-api-key

# OpciÃ³n 4: Hugging Face (Gratuito, sin API key requerida)
LLM_PROVIDER=huggingface
LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.2
HUGGINGFACE_API_KEY=opcional-para-mejores-limites
```

**Nota**: El sistema funciona perfectamente sin LLM. El chatbot **siempre funcionarÃ¡** gracias a su sistema de fallback inteligente:
- Si el LLM configurado falla, intenta automÃ¡ticamente otras APIs gratuitas
- Si todas fallan, usa respuestas contextuales inteligentes basadas en el conocimiento del portal
- Todas las demÃ¡s funcionalidades estÃ¡n disponibles independientemente del estado del LLM

### 5. Configurar LLM (Opcional - Solo para Chatbot)

#### OpciÃ³n 1: Ollama (Recomendado - Gratuito y Local)
```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Windows: Descargar desde https://ollama.ai

# Iniciar servidor
ollama serve

# En otra terminal, descargar modelo
ollama pull llama3
```

#### OpciÃ³n 2: OpenRouter (API Externa)
1. Crear cuenta en [OpenRouter](https://openrouter.ai/)
2. Obtener API key
3. Agregar al archivo `.env`:
```env
LLM_PROVIDER=openrouter
LLM_MODEL=deepseek/deepseek-chat-v3.1:free
OPENROUTER_API_KEY=sk-or-tu-api-key
```

#### OpciÃ³n 3: Hugging Face (Gratuito, sin API key)
El sistema usa Hugging Face por defecto. No requiere configuraciÃ³n adicional, pero puedes agregar una API key para mejores lÃ­mites:
```env
LLM_PROVIDER=huggingface
LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.2
HUGGINGFACE_API_KEY=opcional
```

Ver [CONFIGURAR_LLM.md](./CONFIGURAR_LLM.md) o [CONFIGURAR_LLM_GRATIS.md](./CONFIGURAR_LLM_GRATIS.md) para mÃ¡s detalles.

### 6. Inicializar Base de Datos

El sistema crearÃ¡ automÃ¡ticamente todas las bases de datos necesarias al iniciar por primera vez:

```bash
# Activar entorno virtual si no estÃ¡ activo
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate  # Windows

# Iniciar el servidor (crearÃ¡ las bases de datos automÃ¡ticamente)
python api_server.py
```

**Bases de datos que se crean automÃ¡ticamente:**
- `news_database.db` - ArtÃ­culos y noticias
- `auth_database.db` - Usuarios y autenticaciÃ³n
- `subscription_database.db` - Suscripciones y planes
- `social_media.db` - Datos de redes sociales (si se usa)
- `competitive_intelligence.db` - Inteligencia competitiva (si se usa)
- `trending_predictions.db` - Predicciones trending (si se usa)

**Usuario administrador por defecto:**
- Se crea automÃ¡ticamente al iniciar por primera vez
- **Usuario**: `admin`
- **ContraseÃ±a**: `AdminSecure2024!`
- **Email**: `admin@webscraper.com`

âš ï¸ **IMPORTANTE**: Cambia la contraseÃ±a del admin despuÃ©s del primer inicio en producciÃ³n.

### 7. Verificar InstalaciÃ³n

DespuÃ©s de completar los pasos anteriores, verifica que todo estÃ© funcionando:

```bash
# 1. Verificar que el backend estÃ© corriendo
curl http://localhost:5001/api/health
# DeberÃ­a responder: {"status": "ok"}

# 2. Verificar que el frontend estÃ© accesible
# Abre en el navegador: http://localhost:3001
# DeberÃ­as ver la pÃ¡gina de login

# 3. Iniciar sesiÃ³n con las credenciales por defecto
# Usuario: admin
# ContraseÃ±a: AdminSecure2024!
```

**Si todo funciona correctamente:**
- âœ… VerÃ¡s el Dashboard principal
- âœ… PodrÃ¡s acceder a todas las funcionalidades
- âœ… El sistema estarÃ¡ listo para usar

**Si hay problemas:**
- Revisa la secciÃ³n [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)
- Verifica que todos los prerrequisitos estÃ©n instalados
- AsegÃºrate de que los puertos 5001 y 3001 no estÃ©n ocupados

## ğŸš€ Uso

### Iniciar el Sistema

#### OpciÃ³n 1: Script de Inicio AutomÃ¡tico
```bash
# Ejecutar script que inicia backend y frontend automÃ¡ticamente
chmod +x start_app.sh
./start_app.sh
```

#### OpciÃ³n 2: Inicio Manual

##### 1. Backend (Terminal 1)
```bash
python api_server.py
```
El servidor se ejecutarÃ¡ en `http://localhost:5001`

##### 2. Frontend (Terminal 2)
```bash
cd frontend
npm start
```
La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en `http://localhost:3001` (puerto configurado en `package.json`)

**Nota**: Si el puerto 3001 estÃ¡ ocupado, React te preguntarÃ¡ si quieres usar otro puerto.

### Credenciales por Defecto

El sistema crea automÃ¡ticamente un usuario administrador al iniciar por primera vez:

- **Usuario**: `admin`
- **ContraseÃ±a**: `AdminSecure2024!`
- **Email**: `admin@webscraper.com`

âš ï¸ **IMPORTANTE**: 
- Estas credenciales se crean automÃ¡ticamente solo si no existe ningÃºn usuario en la base de datos
- **Cambia la contraseÃ±a** despuÃ©s del primer inicio en producciÃ³n
- Puedes crear mÃ¡s usuarios desde el panel de administraciÃ³n una vez que inicies sesiÃ³n

## ğŸ“– Funcionalidades Detalladas

### ğŸ  Dashboard Principal
- **Vista general** de estadÃ­sticas en tiempo real
- **Carrusel de anuncios** con rotaciÃ³n automÃ¡tica
- **Comentarios virales** de usuarios
- **Estado del scraping** en tiempo real
- **MÃ©tricas visuales** con grÃ¡ficos y tarjetas informativas
- **Acciones rÃ¡pidas** segÃºn permisos del usuario

### ğŸ” Scraping Manual
1. Ve a la pestaÃ±a **"SCRAPING"**
2. Ingresa la **URL** del sitio web
3. Selecciona el **mÃ©todo** (recomendado: "AnÃ¡lisis Inteligente")
4. Configura **parÃ¡metros** (artÃ­culos, imÃ¡genes, categorÃ­a, regiÃ³n, etc.)
5. Haz clic en **"INICIAR SCRAPING"**
6. **Monitorea** el progreso en tiempo real

### ğŸ“° GestiÃ³n de ArtÃ­culos
1. Ve a la pestaÃ±a **"ARTÃCULOS"**
2. **Filtra** por periÃ³dico, categorÃ­a, regiÃ³n o fecha
3. **Filtros de tiempo**: Ãºltima hora, 24h, 7 dÃ­as, mes, aÃ±o, rango personalizado
4. **Busca** en tÃ­tulos y contenido
5. **Exporta** a Excel con un clic
6. **Visualiza** artÃ­culos individuales con comentarios
7. **PaginaciÃ³n** para navegar grandes volÃºmenes

### ğŸ˜Š AnÃ¡lisis de Sentimientos
1. Ve a la pestaÃ±a **"SENTIMIENTOS"**
2. **Filtra** por categorÃ­a, periÃ³dico, tema o dÃ­as
3. **Visualiza** grÃ¡ficos de:
   - DistribuciÃ³n de sentimientos (positivo/negativo/neutral)
   - Emociones detectadas
   - PolarizaciÃ³n de opiniones
   - EvoluciÃ³n temporal
   - ComparaciÃ³n entre medios
   - ComparaciÃ³n con comentarios virales (Premium/Enterprise)
4. **Alertas** de sentimiento negativo (Premium/Enterprise)
5. **InterpretaciÃ³n** automÃ¡tica de resultados

### ğŸ“¢ GestiÃ³n de Anuncios (Admin)
1. Ve a la pestaÃ±a **"ANUNCIOS"**
2. **Crea campaÃ±as** publicitarias
3. **Gestiona anuncios** por campaÃ±a
4. **Visualiza analytics** y mÃ©tricas
5. **Recibe recomendaciones** de colocaciÃ³n

### ğŸ’¬ Chatbot Inteligente
1. Haz clic en el **botÃ³n flotante de chat** (esquina inferior derecha)
2. **Escribe** tu consulta o usa prompts rÃ¡pidos
3. **Pregunta** por:
   - BÃºsqueda de artÃ­culos: "buscar noticias sobre PerÃº"
   - ResÃºmenes: "resumen selecciÃ³n peruana esta semana"
   - Filtros por fecha: "rpp 2025-01-01 a 2025-12-31"
   - Tu plan: "mi plan"
4. **Recibe respuestas** generadas por LLM o sistema de fallback inteligente

**Sistema de Fallback del Chatbot:**
- El chatbot **siempre responderÃ¡**, incluso si el LLM falla
- Si el LLM configurado no estÃ¡ disponible, el sistema automÃ¡ticamente:
  1. Intenta APIs gratuitas sin key
  2. Intenta el proveedor configurado
  3. Usa Hugging Face como fallback automÃ¡tico
  4. Si todo falla, usa respuestas contextuales inteligentes basadas en el conocimiento del portal
- Las respuestas de fallback son contextuales y Ãºtiles, aunque no tan elaboradas como las del LLM

### ğŸ‘¥ GestiÃ³n de Usuarios (Admin)
1. Ve a la pestaÃ±a **"USUARIOS"**
2. **Crea, edita o elimina** usuarios
3. **Gestiona permisos** dinÃ¡micos por usuario
4. **Asigna roles** (admin/usuario)
5. **Visualiza estadÃ­sticas** de usuarios

### ğŸ’³ Suscripciones
1. Ve a la pestaÃ±a **"SUSCRIPCIONES"**
2. **Visualiza** planes disponibles
3. **Consulta** tu plan actual y lÃ­mites
4. **Gestiona pagos** (admin)

### ğŸ“Š AnÃ¡lisis Avanzado
1. Ve a la pestaÃ±a **"ANÃLISIS"**
2. **Visualiza** tendencias temporales
3. **Analiza** sentimientos por periÃ³dico y categorÃ­a
4. **Revisa** top categorÃ­as y periÃ³dicos
5. **Explora** nube de palabras
6. **Compara** periÃ³dicos con mÃ©tricas detalladas

### ğŸ”® Trending Topics Predictor
1. Ve a la pestaÃ±a **"TRENDING PREDICTOR"**
2. **Genera predicciones** de temas que serÃ¡n trending en 24-48 horas
3. **Visualiza mÃ©tricas**:
   - Nivel de confianza de la predicciÃ³n
   - Potencial viral
   - Tiempo estimado para trending
   - Tasa de crecimiento
4. **Analiza palabras clave** relevantes extraÃ­das automÃ¡ticamente
5. **Consulta historial** de predicciones anteriores
6. **Filtra por categorÃ­a** (General, TecnologÃ­a, PolÃ­tica, etc.)

**Nota**: Requiere anÃ¡lisis de patrones histÃ³ricos. El sistema analiza los Ãºltimos 14 dÃ­as de artÃ­culos para generar predicciones.

### ğŸ” Competitive Intelligence
1. Ve a la pestaÃ±a **"COMPETITIVE INTELLIGENCE"**
2. **Agrega competidores**:
   - Ingresa nombre del competidor
   - Define keywords o dominios a monitorear
   - El sistema detecta automÃ¡ticamente menciones
3. **Visualiza analytics**:
   - Total de menciones por competidor
   - DistribuciÃ³n por periÃ³dico
   - AnÃ¡lisis de sentimiento de menciones
   - Tendencias temporales
4. **Configura alertas** para recibir notificaciones de nuevas menciones
5. **Analiza artÃ­culos existentes** automÃ¡ticamente al agregar un competidor
6. **Recibe sugerencias de IA** para keywords relevantes

**Nota**: El sistema analiza automÃ¡ticamente los Ãºltimos 10,000 artÃ­culos al agregar un nuevo competidor.

### â­ Favoritos
1. Ve a la pestaÃ±a **"FAVORITOS"**
2. **Marca artÃ­culos** como favoritos desde la lista de artÃ­culos
3. **Accede rÃ¡pidamente** a tus artÃ­culos guardados
4. **Filtra y busca** dentro de tus favoritos
5. **Elimina favoritos** cuando ya no los necesites

### ğŸ—„ï¸ ConfiguraciÃ³n de Base de Datos (Admin)
1. Ve a la pestaÃ±a **"BASE DE DATOS"**
2. **Visualiza estadÃ­sticas**:
   - Total de artÃ­culos por periÃ³dico
   - Fechas de primer y Ãºltimo artÃ­culo
   - Total de imÃ¡genes
3. **Limpia datos** por periÃ³dico especÃ­fico
4. **Gestiona bases de datos** del sistema

## âš™ï¸ ConfiguraciÃ³n Avanzada

### MÃ©todos de Scraping

#### ğŸ§  AnÃ¡lisis Inteligente (Recomendado)
- **DetecciÃ³n automÃ¡tica** del mejor mÃ©todo
- **AnÃ¡lisis de pÃ¡gina** (JavaScript, SPA, paginaciÃ³n, lazy loading)
- **RecomendaciÃ³n inteligente** con nivel de confianza
- **DetecciÃ³n de idioma** y clasificaciÃ³n regional

#### ğŸ”„ HÃ­brido
- **Combina Requests y Selenium** para mÃ¡xima compatibilidad
- **Ideal para sitios con JavaScript** dinÃ¡mico
- **Maneja contenido** que se carga asincrÃ³nicamente
- **Fallback automÃ¡tico** entre mÃ©todos

#### âš¡ Optimizado
- **ParalelizaciÃ³n** para mÃ¡ximo rendimiento
- **MÃ¡s rÃ¡pido** para sitios estÃ¡ticos
- **Ideal para sitios** con muchos artÃ­culos
- **MÃºltiples workers** simultÃ¡neos

#### ğŸ› ï¸ Mejorado
- **MÃ©todo robusto** sin Selenium
- **Buena compatibilidad** con la mayorÃ­a de sitios
- **Menor uso de recursos** del sistema
- **Headers inteligentes** y manejo de sesiones

#### ğŸŒ Selenium
- **Navegador completo** con JavaScript
- **Para sitios muy complejos** y SPAs
- **Mayor uso de recursos** pero mÃ¡xima compatibilidad
- **Soporte completo** para contenido dinÃ¡mico

### ConfiguraciÃ³n de LLM

#### Ollama (Recomendado)
```bash
# Instalar Ollama
brew install ollama  # macOS
# O descargar desde: https://ollama.ai

# Iniciar servidor
ollama serve

# Descargar modelo
ollama pull llama3

# Configurar en .env
LLM_PROVIDER=ollama
LLM_MODEL=llama3
```

#### OpenRouter (Alternativa)
```bash
# Crear archivo .env
LLM_PROVIDER=openrouter
LLM_MODEL=deepseek/deepseek-chat-v3.1:free
OPENROUTER_API_KEY=sk-or-tu-api-key-aqui
```

Ver [CONFIGURAR_LLM.md](./CONFIGURAR_LLM.md) para mÃ¡s detalles.

## ğŸ“ Estructura del Proyecto

```
web-scraper-inteligente/
â”œâ”€â”€ ğŸ“ frontend/                    # AplicaciÃ³n React con TypeScript
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/          # Componentes reutilizables
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.tsx          # Barra de navegaciÃ³n
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatbotWidget.tsx   # Chatbot con LLM
â”‚   â”‚   â”‚   â”œâ”€â”€ AdsCarousel.tsx     # Carrusel de anuncios
â”‚   â”‚   â”‚   â”œâ”€â”€ ViralComments.tsx   # Comentarios virales
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ ğŸ“ pages/               # PÃ¡ginas principales
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx      # Dashboard principal
â”‚   â”‚   â”‚   â”œâ”€â”€ ScrapingControl.tsx # Control de scraping
â”‚   â”‚   â”‚   â”œâ”€â”€ ArticlesList.tsx   # Lista de artÃ­culos
â”‚   â”‚   â”‚   â”œâ”€â”€ ImagesGallery.tsx  # GalerÃ­a de imÃ¡genes
â”‚   â”‚   â”‚   â”œâ”€â”€ Analytics.tsx       # AnÃ¡lisis avanzado
â”‚   â”‚   â”‚   â”œâ”€â”€ SentimentAnalysis.tsx # AnÃ¡lisis de sentimientos
â”‚   â”‚   â”‚   â”œâ”€â”€ AdsManagement.tsx  # GestiÃ³n de anuncios
â”‚   â”‚   â”‚   â”œâ”€â”€ UserManagement.tsx # GestiÃ³n de usuarios
â”‚   â”‚   â”‚   â”œâ”€â”€ Subscriptions.tsx  # Suscripciones
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ ğŸ“ services/            # Servicios API
â”‚   â”‚   â”‚   â””â”€â”€ api.ts             # Cliente API
â”‚   â”‚   â”œâ”€â”€ ğŸ“ contexts/           # Contextos React
â”‚   â”‚   â”‚   â”œâ”€â”€ AuthContext.tsx    # AutenticaciÃ³n
â”‚   â”‚   â”‚   â””â”€â”€ ThemeContext.tsx   # Tema
â”‚   â”‚   â””â”€â”€ App.tsx                # Componente principal
â”‚   â”œâ”€â”€ package.json               # Dependencias Node.js
â”‚   â””â”€â”€ tsconfig.json              # ConfiguraciÃ³n TypeScript
â”œâ”€â”€ ğŸ“ scraped_images/             # ImÃ¡genes descargadas
â”œâ”€â”€ ğŸ“„ api_server.py              # Servidor Flask REST API
â”œâ”€â”€ ğŸ“„ auth_system.py              # Sistema de autenticaciÃ³n
â”œâ”€â”€ ğŸ“„ subscription_system.py     # Sistema de suscripciones
â”œâ”€â”€ ğŸ“„ sentiment_analyzer.py      # Analizador de sentimientos
â”œâ”€â”€ ğŸ“„ ads_system.py              # Sistema de anuncios
â”œâ”€â”€ ğŸ“„ auto_scraper_standalone.py # Scraper automÃ¡tico independiente
â”œâ”€â”€ ğŸ“„ auto_scraping_config.json  # ConfiguraciÃ³n de scraping automÃ¡tico
â”œâ”€â”€ ğŸ“„ hybrid_crawler.py         # Scraper hÃ­brido
â”œâ”€â”€ ğŸ“„ optimized_scraper.py      # Scraper optimizado
â”œâ”€â”€ ğŸ“„ improved_scraper.py        # Scraper mejorado
â”œâ”€â”€ ğŸ“„ intelligent_analyzer.py   # Analizador inteligente
â”œâ”€â”€ ğŸ“„ news_database.db          # Base de datos SQLite principal
â”œâ”€â”€ ğŸ“„ requirements.txt          # Dependencias Python
â”œâ”€â”€ ğŸ“„ .env.example              # Ejemplo de configuraciÃ³n
â”œâ”€â”€ ğŸ“„ CONFIGURAR_LLM.md         # GuÃ­a de configuraciÃ³n LLM
â”œâ”€â”€ ğŸ“„ DESCRIPCION_ANALISIS.md   # DescripciÃ³n del anÃ¡lisis
â””â”€â”€ ğŸ“„ README.md                 # Este archivo
```

## ğŸ“¦ Â¿Por quÃ© hay tantos archivos en el repositorio?

Este proyecto contiene una gran cantidad de archivos debido a su naturaleza como sistema completo de scraping y anÃ¡lisis. A continuaciÃ³n se explica la razÃ³n de cada tipo de archivo:

### ğŸ”§ Archivos de CÃ³digo Fuente (Esenciales)

#### Scripts de Scraping (MÃºltiples MÃ©todos)
- **`intelligent_analyzer.py`** - Analizador inteligente que detecta el mejor mÃ©todo
- **`hybrid_crawler.py`** - Scraper hÃ­brido (combina Requests + Selenium)
- **`optimized_scraper.py`** - Scraper optimizado con paralelizaciÃ³n
- **`improved_scraper.py`** - Scraper mejorado sin Selenium
- **`auto_scraper_standalone.py`** - Scraper automÃ¡tico independiente
- **`elperuano_scraper.py`** - Scraper especÃ­fico para El Peruano
- **`elperuano_selenium_scraper.py`** - VersiÃ³n Selenium para El Peruano

**RazÃ³n**: Cada mÃ©todo de scraping tiene ventajas para diferentes tipos de sitios web. El sistema prueba automÃ¡ticamente el mejor mÃ©todo segÃºn las caracterÃ­sticas de cada pÃ¡gina.

#### Scripts de Redes Sociales (Proyecto AcadÃ©mico)
- **`facebook_graph_scraper.py`** - Scraper de Facebook usando Graph API
- **`facebook_manual_scraper.py`** - Scraper manual de Facebook
- **`reddit_api_scraper.py`** - Scraper de Reddit usando API
- **`reddit_selenium_scraper.py`** - Scraper de Reddit con Selenium
- **`youtube_api_scraper.py`** - Scraper de YouTube usando API
- **`youtube_selenium_scraper.py`** - Scraper de YouTube con Selenium
- **`social_media_scraper.py`** - Scraper unificado de redes sociales
- **`social_media_processor.py`** - Procesador de datos de redes sociales
- **`social_media_db.py`** - GestiÃ³n de base de datos de redes sociales

**RazÃ³n**: Cada red social requiere mÃ©todos diferentes de scraping. Algunas tienen APIs oficiales, otras requieren Selenium. Estos scripts permiten extraer datos de mÃºltiples plataformas.

#### Sistemas Especializados
- **`api_server.py`** - Servidor Flask principal (API REST)
- **`auth_system.py`** - Sistema de autenticaciÃ³n y permisos
- **`subscription_system.py`** - Sistema de suscripciones y planes
- **`sentiment_analyzer.py`** - Analizador de sentimientos
- **`ads_system.py`** - Sistema de gestiÃ³n de anuncios
- **`trending_predictor_system.py`** - Predictor de temas trending
- **`competitive_intelligence_system.py`** - Sistema de inteligencia competitiva
- **`ai_keyword_analyzer.py`** - Analizador de palabras clave con IA

**RazÃ³n**: Cada sistema es un mÃ³dulo independiente que puede funcionar por separado o integrarse con el sistema principal.

#### Scripts de ConfiguraciÃ³n y Utilidades
- **`configure_mysql.py`** - ConfiguraciÃ³n de MySQL (opcional)
- **`setup_auto_scraping.py`** - ConfiguraciÃ³n de scraping automÃ¡tico
- **`manage_auto_scraping.py`** - GestiÃ³n de scraping automÃ¡tico
- **`migrate_database.py`** - MigraciÃ³n de base de datos
- **`init_competitive_intelligence.py`** - InicializaciÃ³n de inteligencia competitiva
- **`test_*.py`** - Scripts de prueba para diferentes componentes

**RazÃ³n**: Estos scripts facilitan la configuraciÃ³n, migraciÃ³n y pruebas del sistema.

#### Scripts de Inicio y GestiÃ³n
- **`start_app.sh`** - Inicia backend y frontend automÃ¡ticamente
- **`start_simple.sh`** - Inicio simplificado
- **`start_websocket.sh`** - Inicia servidor WebSocket
- **`clean_and_restart.sh`** - Limpia y reinicia el sistema
- **`restart_system.sh`** - Reinicia el sistema
- **`restart_clean.sh`** - Reinicio con limpieza
- **`force_restart.sh`** - Reinicio forzado
- **`run_auto_scraping.sh`** - Ejecuta scraping automÃ¡tico

**RazÃ³n**: Diferentes scripts para diferentes escenarios de uso (desarrollo, producciÃ³n, limpieza, etc.).

### ğŸ“„ Archivos de Datos Generados

#### Archivos JSON de Redes Sociales
- **`facebook_posts_*.json`** (mÃºltiples archivos) - Datos extraÃ­dos de Facebook durante pruebas

**RazÃ³n**: Estos archivos son resultado de pruebas y scraping de redes sociales. Son datos de ejemplo que demuestran la funcionalidad del sistema. Pueden eliminarse si no se necesitan.

#### ImÃ¡genes Descargadas
- **`scraped_images/`** (1,500+ imÃ¡genes) - ImÃ¡genes descargadas de los artÃ­culos scraped

**RazÃ³n**: El sistema descarga automÃ¡ticamente las imÃ¡genes de los artÃ­culos para mostrarlas en la galerÃ­a. Estas imÃ¡genes son parte de los datos extraÃ­dos y se almacenan localmente.

### ğŸ“š Archivos de DocumentaciÃ³n

#### DocumentaciÃ³n Principal
- **`README.md`** - Este archivo (documentaciÃ³n principal)
- **`CAMBIOS_SESION.md`** - Registro de cambios de la sesiÃ³n actual
- **`INSTALACION.md`** - GuÃ­a de instalaciÃ³n detallada
- **`MANUAL_USUARIO.md`** - Manual de usuario completo

#### DocumentaciÃ³n de Funcionalidades EspecÃ­ficas
- **`CONFIGURAR_LLM.md`** - ConfiguraciÃ³n del chatbot con LLM
- **`CONFIGURAR_LLM_GRATIS.md`** - ConfiguraciÃ³n de LLM gratuito
- **`CONFIGURAR_TOKEN.md`** - ConfiguraciÃ³n de tokens de API
- **`PASOS_CREAR_TOKEN.md`** - Pasos para crear tokens
- **`README_AUTH.md`** - DocumentaciÃ³n del sistema de autenticaciÃ³n
- **`README_SUBSCRIPTIONS.md`** - DocumentaciÃ³n de suscripciones
- **`README_SOCIAL_MEDIA.md`** - DocumentaciÃ³n de redes sociales
- **`README_SOCIAL_MEDIA_SCRAPING.md`** - GuÃ­a de scraping de redes sociales

#### DocumentaciÃ³n de InvestigaciÃ³n
- **`FACEBOOK_SCRAPING_RESEARCH.md`** - InvestigaciÃ³n sobre scraping de Facebook
- **`REDDIT_SCRAPING_RESEARCH.md`** - InvestigaciÃ³n sobre scraping de Reddit
- **`YOUTUBE_SCRAPING_RESEARCH.md`** - InvestigaciÃ³n sobre scraping de YouTube
- **`INSTRUCCIONES_GRAPH_API.md`** - Instrucciones para Graph API

#### DocumentaciÃ³n de Negocio
- **`MONETIZACION_DETALLADA.md`** - Estrategia de monetizaciÃ³n
- **`PLAN_NEGOCIO_MONETIZACION.md`** - Plan de negocio y monetizaciÃ³n
- **`DESCRIPCION_ANALISIS.md`** - DescripciÃ³n del anÃ¡lisis de sentimientos
- **`solucion_permisos.md`** - SoluciÃ³n de problemas de permisos

**RazÃ³n**: DocumentaciÃ³n completa para facilitar el uso, configuraciÃ³n y mantenimiento del sistema.

### ğŸ—„ï¸ Bases de Datos

- **`news_database.db`** - Base de datos principal de artÃ­culos
- **`auth_database.db`** - Base de datos de autenticaciÃ³n
- **`subscription_database.db`** - Base de datos de suscripciones
- **`social_media.db`** - Base de datos de redes sociales
- **`competitive_intelligence.db`** - Base de datos de inteligencia competitiva
- **`trending_predictions.db`** - Base de datos de predicciones trending
- **`*.db`** (mÃºltiples) - Bases de datos de respaldo y pruebas

**RazÃ³n**: Cada mÃ³dulo tiene su propia base de datos para mantener la separaciÃ³n de responsabilidades y facilitar el mantenimiento.

### ğŸ§¹ Limpieza de Archivos (Opcional)

Si deseas reducir el tamaÃ±o del repositorio, puedes eliminar:

1. **Archivos JSON de prueba**: `facebook_posts_*.json` (si no los necesitas)
2. **ImÃ¡genes descargadas**: `scraped_images/` (se regenerarÃ¡n al hacer scraping)
3. **Bases de datos de respaldo**: `*_backup.db`, `news_database_backup.db`
4. **Logs**: `*.log` (se regeneran automÃ¡ticamente)
5. **Archivos PID**: `*.pid` (archivos temporales de procesos)

**Nota**: Los archivos `.gitignore` ya estÃ¡ configurado para ignorar bases de datos, logs y archivos temporales en futuros commits.

### ğŸ“Š Resumen de Archivos por CategorÃ­a

| CategorÃ­a | Cantidad Aprox. | PropÃ³sito |
|-----------|----------------|-----------|
| **Scripts Python** | ~30 | LÃ³gica del sistema |
| **Scripts Shell** | ~8 | AutomatizaciÃ³n y gestiÃ³n |
| **Componentes React** | ~20 | Interfaz de usuario |
| **PÃ¡ginas React** | ~15 | PÃ¡ginas principales |
| **DocumentaciÃ³n** | ~20 | GuÃ­as y manuales |
| **ImÃ¡genes** | 1,500+ | Contenido descargado |
| **JSON de prueba** | ~15 | Datos de ejemplo |
| **Bases de datos** | ~8 | Almacenamiento de datos |

**Total**: ~1,600+ archivos (incluyendo imÃ¡genes y datos generados)

### âœ… Archivos Esenciales vs Opcionales

#### âœ… Esenciales (No eliminar)
- Todos los scripts `.py` de scraping y sistemas
- Todos los componentes y pÃ¡ginas de React
- `requirements.txt`, `package.json`
- Archivos de configuraciÃ³n (`.json`, `.env.example`)
- DocumentaciÃ³n principal (`README.md`, `INSTALACION.md`)

#### âš ï¸ Opcionales (Pueden eliminarse)
- `facebook_posts_*.json` - Datos de prueba
- `scraped_images/` - Se regeneran automÃ¡ticamente
- Bases de datos de respaldo (`*_backup.db`)
- Logs (`*.log`)
- Archivos PID (`*.pid`)

## ğŸš€ Funcionalidades Avanzadas

### ğŸ”„ Sistema de Scraping AutomÃ¡tico
- **EjecuciÃ³n programada** cada 5 minutos con cron
- **Scraping independiente** sin necesidad de servidor API
- **PrevenciÃ³n de duplicados** automÃ¡tica
- **Logging detallado** de todas las operaciones
- **ConfiguraciÃ³n flexible** por periÃ³dico

### ğŸ§  AnÃ¡lisis Inteligente de PÃ¡ginas
- **DetecciÃ³n automÃ¡tica** de caracterÃ­sticas de pÃ¡gina
- **AnÃ¡lisis de JavaScript** y contenido dinÃ¡mico
- **DetecciÃ³n de paginaciÃ³n** y lazy loading
- **RecomendaciÃ³n de mÃ©todo** con nivel de confianza
- **ClasificaciÃ³n regional** automÃ¡tica (Nacional/Extranjero)

### ğŸ“Š GestiÃ³n Avanzada de Datos
- **Base de datos SQLite** optimizada con mÃºltiples tablas
- **ExportaciÃ³n a Excel** con formato profesional
- **Filtros mÃºltiples** (periÃ³dico, categorÃ­a, regiÃ³n, fecha)
- **BÃºsqueda de texto** en contenido completo
- **PaginaciÃ³n** para grandes volÃºmenes de datos
- **Comentarios** en artÃ­culos

### ğŸ¨ Interfaz de Usuario Moderna
- **Dashboard en tiempo real** con mÃ©tricas actualizadas
- **Sistema de notificaciones** para eventos importantes
- **DiseÃ±o responsivo** compatible con mÃ³viles
- **Temas modernos** con Material-UI
- **GrÃ¡ficos interactivos** (ECharts) para anÃ¡lisis de datos
- **Chatbot flotante** siempre accesible

### ğŸ”§ Herramientas de AdministraciÃ³n
- **GestiÃ³n de usuarios** con permisos dinÃ¡micos
- **GestiÃ³n de anuncios** y campaÃ±as
- **Limpieza masiva** de datos
- **ConfiguraciÃ³n de base de datos** MySQL opcional
- **Monitoreo de estado** del sistema
- **Logs detallados** para debugging

## ğŸ“ˆ Planes de SuscripciÃ³n

### ğŸ†“ Freemium
- âœ… Scraping bÃ¡sico
- âœ… AnÃ¡lisis de sentimientos bÃ¡sico
- âœ… VisualizaciÃ³n de artÃ­culos
- âœ… BÃºsqueda y filtros
- âš ï¸ LÃ­mites: 100 artÃ­culos/dÃ­a, 10 mensajes chat/dÃ­a

### ğŸ’ Premium
- âœ… Todo lo de Freemium
- âœ… AnÃ¡lisis de sentimientos avanzado
- âœ… ComparaciÃ³n con comentarios virales
- âœ… Alertas de sentimiento negativo
- âœ… ExportaciÃ³n a Excel/CSV
- âš ï¸ LÃ­mites: 500 artÃ­culos/dÃ­a, 50 mensajes chat/dÃ­a

### ğŸ¢ Enterprise
- âœ… Todo lo de Premium
- âœ… IntegraciÃ³n inteligente de anuncios
- âœ… Sin lÃ­mites de uso
- âœ… API access
- âœ… Soporte prioritario
- âœ… PersonalizaciÃ³n avanzada

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "Connection refused"
```bash
# Verificar que el backend estÃ© corriendo
curl http://localhost:5001/api/health
```

### Error: "ChromeDriver not found"
```bash
# El sistema descarga automÃ¡ticamente ChromeDriver usando webdriver-manager
# Si falla, verifica que tengas Chrome o Chromium instalado:

# macOS
brew install --cask google-chrome

# Linux (Ubuntu/Debian)
sudo apt-get update
sudo apt-get install google-chrome-stable

# Windows: Descargar desde https://www.google.com/chrome/

# Si el problema persiste, el sistema intentarÃ¡ usar undetected-chromedriver
# que descarga el driver automÃ¡ticamente
```

### Error: "Module not found"
```bash
# Reinstalar dependencias
pip install -r requirements.txt
cd frontend && npm install
```

### Chatbot no funciona o responde con fallback
```bash
# El chatbot SIEMPRE funciona, incluso sin LLM configurado.
# Si el LLM falla, usa un sistema de fallback inteligente.

# 1. Verificar estado del LLM
curl http://localhost:5001/api/llm/status

# 2. Si usa Ollama, verificar que estÃ© corriendo
curl http://localhost:11434/api/tags

# 3. Sistema de Fallback del Chatbot:
#    - Si el LLM configurado falla, intenta automÃ¡ticamente APIs gratuitas
#    - Si todas fallan, usa respuestas contextuales inteligentes
#    - El chatbot SIEMPRE responderÃ¡, aunque sea con fallback

# 4. Para mejorar las respuestas del chatbot, configura un LLM:
#    - CONFIGURAR_LLM_GRATIS.md - Para opciones gratuitas
#    - CONFIGURAR_LLM.md - Para configuraciÃ³n completa
#    - O instalar Ollama: https://ollama.ai

# 5. Orden de intentos del sistema:
#    1. APIs gratuitas sin key (Together AI, Perplexity, DeepInfra)
#    2. Proveedor configurado (Groq, Hugging Face, OpenRouter, Ollama)
#    3. Hugging Face como fallback automÃ¡tico
#    4. Sistema de respuestas inteligentes (siempre disponible)
```

### Scraping automÃ¡tico no funciona
```bash
# Verificar cron
crontab -l

# Verificar logs
tail -f auto_scraping.log
```

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ‘¨â€ğŸ’» Autor

**AlexCoilaJrt**
- GitHub: [@AlexCoilaJrt](https://github.com/AlexCoilaJrt)
- Repositorio: [webscraper](https://github.com/AlexCoilaJrt/webscraper)

## ğŸ™ Agradecimientos

- **BeautifulSoup** por el parsing HTML
- **Selenium** por la automatizaciÃ³n de navegador
- **Material-UI** por los componentes React
- **ECharts** por las visualizaciones avanzadas
- **Flask** por el framework web
- **VADER Sentiment** por el anÃ¡lisis de sentimientos
- **Ollama** por el LLM local gratuito

---

## ğŸ“ Soporte

Si tienes problemas o preguntas:

1. **Revisa** la secciÃ³n de soluciÃ³n de problemas
2. **Consulta** los issues existentes en GitHub
3. **Crea** un nuevo issue con detalles del problema
4. **Revisa** la documentaciÃ³n adicional:
   - [CONFIGURAR_LLM.md](./CONFIGURAR_LLM.md) - ConfiguraciÃ³n del chatbot
   - [DESCRIPCION_ANALISIS.md](./DESCRIPCION_ANALISIS.md) - DescripciÃ³n del anÃ¡lisis
   - [README_AUTH.md](./README_AUTH.md) - Sistema de autenticaciÃ³n
   - [README_SUBSCRIPTIONS.md](./README_SUBSCRIPTIONS.md) - Sistema de suscripciones

---

â­ **Â¡Si te gusta este proyecto, no olvides darle una estrella en GitHub!** â­
