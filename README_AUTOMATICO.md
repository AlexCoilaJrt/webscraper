# ğŸ¤– Sistema de Scraping AutomÃ¡tico

## ğŸ“‹ **Â¿QuÃ© es un Crawler?**

Un **crawler** (tambiÃ©n llamado "web crawler", "spider" o "bot") es un programa automatizado que:

1. **ğŸ•·ï¸ Navega por sitios web** siguiendo enlaces automÃ¡ticamente
2. **ğŸ“„ Extrae informaciÃ³n** de las pÃ¡ginas que visita
3. **ğŸ—‚ï¸ Indexa y organiza** el contenido encontrado
4. **âš¡ Funciona de manera sistemÃ¡tica** y automatizada

## ğŸ¯ **Â¿CÃ³mo te ayuda en tu sistema?**

Tu sistema ahora tiene **3 tipos de crawlers**:

### **1. ğŸš€ HybridDataCrawler** (`hybrid_crawler.py`)
- **Combina** Requests + Selenium para mÃ¡xima eficiencia
- **Detecta automÃ¡ticamente** si una pÃ¡gina necesita JavaScript
- **Fallback inteligente** si Selenium falla
- **Ideal para**: Sitios dinÃ¡micos como El Comercio, PerÃº21

### **2. âš¡ SmartScraper** (`optimized_scraper.py`)
- **Scraping paralelo** con mÃºltiples hilos
- **Cache inteligente** para evitar duplicados
- **ExtracciÃ³n optimizada** de enlaces y contenido
- **Ideal para**: Sitios con mucho contenido como El Popular

### **3. ğŸ”§ MÃ©todo BÃ¡sico** (fallback)
- **Requests + BeautifulSoup** para sitios simples
- **ExtracciÃ³n bÃ¡sica** de enlaces
- **Ideal para**: Sitios estÃ¡ticos o como respaldo

## ğŸ• **Sistema de AutomatizaciÃ³n**

### **ğŸ“… ProgramaciÃ³n AutomÃ¡tica**
Tu sistema ahora se ejecuta automÃ¡ticamente:

- **ğŸŒ… 8:00 AM** - Noticias matutinas (El Comercio)
- **ğŸŒ 12:00 PM** - Diario Sin Fronteras
- **ğŸŒ† 6:00 PM** - Noticias vespertinas (El Popular)

### **ğŸ® GestiÃ³n del Sistema**

```bash
# Ver estado del sistema
python manage_auto_scraping.py status

# Ejecutar scraping ahora
python manage_auto_scraping.py run

# Ver logs recientes
python manage_auto_scraping.py logs

# Habilitar/deshabilitar
python manage_auto_scraping.py enable
python manage_auto_scraping.py disable
```

## ğŸ”§ **ConfiguraciÃ³n de Cron Jobs**

### **OpciÃ³n 1: ConfiguraciÃ³n AutomÃ¡tica**
```bash
./setup_cron.sh
```

### **OpciÃ³n 2: ConfiguraciÃ³n Manual**
```bash
# Abrir crontab
crontab -e

# Agregar estas lÃ­neas:
0 8 * * * /Users/usuario/Documents/scraping\ 2/run_auto_scraping.sh
0 12 * * * /Users/usuario/Documents/scraping\ 2/run_auto_scraping.sh
0 18 * * * /Users/usuario/Documents/scraping\ 2/run_auto_scraping.sh

# Guardar y salir (Ctrl+X, Y, Enter)
```

### **ğŸ“‹ Verificar Cron Jobs**
```bash
# Ver cron jobs configurados
crontab -l

# Ver logs del sistema
tail -f auto_scraping.log
```

## ğŸ“Š **Resultados del Sistema**

### **âœ… Lo que se extrae automÃ¡ticamente:**
- **ğŸ“° ArtÃ­culos** con tÃ­tulo, contenido, URL, fecha
- **ğŸ–¼ï¸ ImÃ¡genes** descargadas y organizadas
- **ğŸ“ˆ EstadÃ­sticas** de scraping por sesiÃ³n
- **ğŸ·ï¸ Metadatos** (categorÃ­a, periÃ³dico, regiÃ³n)

### **ğŸ’¾ Almacenamiento:**
- **Base de datos**: `scraping_data.db`
- **ImÃ¡genes**: Carpeta `scraped_images/`
- **Logs**: `auto_scraping.log`

## ğŸ¯ **Ventajas del Sistema AutomÃ¡tico**

### **1. ğŸ• ActualizaciÃ³n Continua**
- **Sin intervenciÃ³n manual** - se ejecuta solo
- **Captura noticias frescas** diariamente
- **Mantiene tu base de datos actualizada**

### **2. ğŸš€ Eficiencia**
- **MÃºltiples mÃ©todos** de scraping
- **Cache inteligente** evita duplicados
- **Procesamiento paralelo** para velocidad

### **3. ğŸ“Š Monitoreo**
- **Logs detallados** de cada ejecuciÃ³n
- **EstadÃ­sticas** de rendimiento
- **Control total** del sistema

### **4. ğŸ”§ Flexibilidad**
- **ConfiguraciÃ³n fÃ¡cil** de horarios
- **MÃºltiples fuentes** de noticias
- **Habilitar/deshabilitar** segÃºn necesidad

## ğŸ› ï¸ **Archivos del Sistema**

```
ğŸ“ scraping 2/
â”œâ”€â”€ ğŸ¤– auto_scraper_standalone.py      # Script principal
â”œâ”€â”€ âš™ï¸ auto_scraping_config.json       # ConfiguraciÃ³n
â”œâ”€â”€ ğŸš€ run_auto_scraping.sh            # Script de cron
â”œâ”€â”€ ğŸ® manage_auto_scraping.py         # GestiÃ³n del sistema
â”œâ”€â”€ ğŸ”§ setup_cron.sh                   # ConfiguraciÃ³n automÃ¡tica
â”œâ”€â”€ ğŸ’¾ scraping_data.db                # Base de datos
â”œâ”€â”€ ğŸ“‹ auto_scraping.log               # Logs del sistema
â””â”€â”€ ğŸ–¼ï¸ scraped_images/                 # ImÃ¡genes descargadas
```

## ğŸ‰ **Â¡Tu Sistema EstÃ¡ Listo!**

### **âœ… Lo que tienes ahora:**
1. **ğŸ¤– Scraping automÃ¡tico** que se ejecuta solo
2. **ğŸ“… ProgramaciÃ³n flexible** de horarios
3. **ğŸ® Control total** del sistema
4. **ğŸ“Š Monitoreo completo** con logs
5. **ğŸ’¾ Almacenamiento organizado** de datos

### **ğŸš€ PrÃ³ximos pasos:**
1. **Configurar cron jobs**: `./setup_cron.sh`
2. **Probar el sistema**: `python manage_auto_scraping.py run`
3. **Monitorear logs**: `tail -f auto_scraping.log`
4. **Personalizar horarios** en `auto_scraping_config.json`

Â¡Tu sistema de web scraping ahora es completamente automÃ¡tico y se mantiene actualizado sin intervenciÃ³n manual! ğŸŠ

