# üì± Gu√≠a de Scraping de Redes Sociales - Mejorado

## üéØ Caracter√≠sticas Principales

Este sistema mejorado de scraping de redes sociales incluye:

### ‚úÖ **Extracci√≥n Completa de Contenido**
- **Expansi√≥n autom√°tica** de contenido colapsado ("Ver m√°s", "Show more")
- **Texto completo** sin truncar
- **Preservaci√≥n de emojis** y caracteres especiales
- **Manejo inteligente** de contenido din√°mico

### ‚úÖ **Extracci√≥n Mejorada de Im√°genes/Media**
- **URLs reales** de im√°genes (no placeholders)
- **Validaci√≥n de URLs** para asegurar que sean accesibles
- **Filtrado de avatares** y perfiles
- **Soporte para videos** (Facebook)
- **Detecci√≥n de im√°genes de contenido** vs. im√°genes de UI

### ‚úÖ **M√©tricas Precisas**
- **Parseo mejorado** de formatos abreviados (1.2K ‚Üí 1200, 5M ‚Üí 5000000)
- **Selectores espec√≠ficos** para likes, retweets, comentarios
- **Fallback robusto** si los selectores principales fallan

### ‚úÖ **Categorizaci√≥n Inteligente**
- **Keywords expandidas** para 6 categor√≠as principales
- **Scoring ponderado** por frecuencia de palabras clave
- **Categor√≠as**: tecnolog√≠a, deportes, pol√≠tica, entretenimiento, negocios, salud

### ‚úÖ **An√°lisis de Sentimiento Preciso**
- **VADER Sentiment** (preferido para redes sociales)
- **TextBlob** como fallback
- **An√°lisis b√°sico** como √∫ltimo recurso
- **Umbrales precisos**: positivo > 0.05, negativo < -0.05

### ‚úÖ **Retry Logic y Validaci√≥n**
- **3 intentos** por elemento si falla la extracci√≥n
- **Validaci√≥n de datos** antes de guardar
- **Manejo robusto de errores** con logs detallados

---

## üöÄ Instalaci√≥n

### 1. Instalar Dependencias

```bash
pip install -r requirements.txt
```

**Nuevas dependencias agregadas:**
- `textblob==0.17.1` - An√°lisis de sentimiento
- `vaderSentiment==3.3.2` - An√°lisis de sentimiento para redes sociales
- `nltk==3.8.1` - Procesamiento de lenguaje natural

### 2. Descargar Datos de NLTK (opcional)

Si usas TextBlob, necesitas descargar datos de NLTK:

```python
import nltk
nltk.download('punkt')
nltk.download('brown')
nltk.download('wordnet')
```

---

## üìñ Uso

### Ejemplo B√°sico - Twitter/X

```python
from social_media_scraper import TwitterScraper
from social_media_processor import SocialMediaProcessor

# Crear scraper
scraper = TwitterScraper(headless=True, delay=3)

# Scrapear desde URL
posts = scraper.scrape_from_url(
    url="https://twitter.com/search?q=tecnologia",
    max_tweets=50
)

# Procesar posts
processor = SocialMediaProcessor()
processed_posts = processor.process_batch(posts)

# Mostrar resultados
for post in processed_posts:
    print(f"Usuario: {post['username']}")
    print(f"Texto: {post['text']}")
    print(f"Imagen: {post.get('image_url', 'N/A')}")
    print(f"Likes: {post['likes']}")
    print(f"Categor√≠a: {post['category']}")
    print(f"Sentimiento: {post['sentiment']}")
    print("-" * 60)

scraper.close()
```

### Ejemplo B√°sico - Facebook

```python
from social_media_scraper import FacebookScraper
from social_media_processor import SocialMediaProcessor

# Crear scraper
scraper = FacebookScraper(headless=True, delay=3)

# Scrapear desde URL
posts = scraper.scrape_from_url(
    url="https://www.facebook.com/facebook",
    max_posts=50
)

# Procesar posts
processor = SocialMediaProcessor()
processed_posts = processor.process_batch(posts)

scraper.close()
```

---

## üîß Selectores CSS/XPath Actualizados

### Twitter/X

| Elemento | Selector |
|----------|----------|
| **Texto del tweet** | `div[data-testid="tweetText"]` o `span[data-testid="tweetText"]` |
| **Autor** | `a[href*="/user"]` o `span` con `@username` |
| **Likes** | `span[data-testid="like"]` o `button[data-testid="like"]` |
| **Retweets** | `span[data-testid="retweet"]` o `button[data-testid="retweet"]` |
| **Respuestas** | `span[data-testid="reply"]` o `button[data-testid="reply"]` |
| **Im√°genes** | `div[data-testid*="media"] img` o `img[src*="pbs.twimg.com"]` |
| **Posts** | `article[data-testid="tweet"]` |

### Facebook

| Elemento | Selector |
|----------|----------|
| **Texto del post** | `div[data-ad-preview="message"]` o `div[data-testid="post_message"]` |
| **Autor** | `a[href*="/pages/"]` o `span.x1lliihq.x1plvlek` |
| **Reacciones** | `span[aria-label*="reaction"]` o texto con "like", "me gusta" |
| **Comentarios** | `span[aria-label*="comment"]` o texto con "comment", "comentario" |
| **Compartidos** | `span[aria-label*="share"]` o texto con "share", "compartir" |
| **Im√°genes** | `img[src*="fbcdn.net"]` o `img[data-visualcompletion="media-vc-image"]` |
| **Posts** | `div[data-pagelet]` o `div[role="article"]` |

---

## üß™ Testing

### Ejecutar Script de Prueba

```bash
python test_social_media_extraction.py
```

Este script valida:
- ‚úÖ Contenido completo sin truncar
- ‚úÖ URLs de im√°genes v√°lidas (no null)
- ‚úÖ M√©tricas num√©ricas correctas
- ‚úÖ Categor√≠a relevante
- ‚úÖ Sentimiento preciso

---

## üîç Troubleshooting Com√∫n

### ‚ùå Problema: "No se extraen posts"

**Causas posibles:**
1. **Requiere autenticaci√≥n**: Twitter/Facebook bloquean el acceso sin login
2. **Selectores desactualizados**: Las plataformas cambian su HTML frecuentemente
3. **Timeout**: La p√°gina no carga a tiempo

**Soluciones:**
- Verificar que la URL sea p√∫blica y accesible
- Aumentar el delay: `scraper = TwitterScraper(delay=5)`
- Verificar logs para ver qu√© selectores est√°n fallando
- Intentar con modo no-headless para ver qu√© est√° pasando: `headless=False`

### ‚ùå Problema: "image_url: null"

**Causas posibles:**
1. El post no tiene imagen
2. La imagen est√° cargada din√°micamente (lazy loading)
3. Los selectores de imagen no funcionan

**Soluciones:**
- Verificar que el post realmente tenga imagen
- Aumentar tiempo de espera antes de extraer: `time.sleep(5)`
- Hacer scroll para cargar im√°genes lazy: `driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")`
- Revisar logs para ver si se detectan im√°genes pero se filtran

### ‚ùå Problema: "M√©tricas incorrectas (0 o muy altas)"

**Causas posibles:**
1. Formato abreviado no se parsea correctamente ("1.2K" ‚Üí 1200)
2. Selectores de m√©tricas no funcionan
3. M√©tricas est√°n en otro formato

**Soluciones:**
- Verificar que el parseo de m√©tricas funcione: `scraper._parse_metric("1.2K")` debe retornar `1200`
- Revisar HTML del post para ver el formato real de las m√©tricas
- Usar fallback de b√∫squeda por contexto si selectores espec√≠ficos fallan

### ‚ùå Problema: "Categor√≠a siempre es 'general'"

**Causas posibles:**
1. El texto no contiene palabras clave conocidas
2. El texto est√° muy corto o truncado
3. Las palabras clave no coinciden

**Soluciones:**
- Verificar que el texto completo se extraiga (no truncado)
- Agregar m√°s palabras clave a `category_keywords` en `social_media_processor.py`
- Reducir el umbral de scoring: cambiar `>= 2` a `>= 1` en `categorize_tweet`

### ‚ùå Problema: "Sentimiento siempre es 'neutral'"

**Causas posibles:**
1. VADER/TextBlob no est√°n instalados
2. El texto es muy corto
3. El texto no tiene palabras con carga emocional

**Soluciones:**
- Verificar instalaci√≥n: `pip install vaderSentiment textblob`
- Verificar que el texto se extraiga completo
- Probar manualmente: `analyzer = SentimentIntensityAnalyzer(); analyzer.polarity_scores("I love this!")`

### ‚ùå Problema: "Error: 'WebDriver' no encontrado"

**Causas posibles:**
1. ChromeDriver/EdgeDriver no est√° instalado
2. webdriver-manager no puede descargar el driver

**Soluciones:**
- Instalar webdriver-manager: `pip install webdriver-manager`
- Verificar que Chrome/Edge est√© instalado
- Usar versi√≥n espec√≠fica: `ChromeDriverManager(version="120.0.0.0").install()`

### ‚ùå Problema: "Timeout en carga de p√°gina"

**Causas posibles:**
1. Conexi√≥n lenta
2. La p√°gina tarda mucho en cargar
3. Hay demasiados elementos que cargar

**Soluciones:**
- Aumentar timeout: `driver.set_page_load_timeout(60)`
- Reducir max_posts para pruebas: `max_posts=10`
- Usar delays m√°s largos: `delay=5`

---

## üìä Estructura de Datos Extra√≠dos

```python
{
    "platform": "twitter" | "facebook",
    "username": "@username" o "Page Name",
    "text": "Texto completo del post...",
    "cleaned_text": "Texto limpio sin URLs...",
    "date": "2025-01-15T10:30:00",
    "likes": 1992,
    "retweets": 0,  # Solo Twitter
    "replies": 293,  # Twitter
    "comments": 293,  # Facebook
    "shares": 150,  # Facebook
    "hashtags": ["#tecnologia", "#IA"],
    "url": "https://twitter.com/user/status/123456",
    "image_url": "https://pbs.twimg.com/media/...",
    "video_url": "https://fbcdn.net/...",  # Solo Facebook
    "category": "tecnolog√≠a",
    "sentiment": "positive" | "negative" | "neutral",
    "detected_language": "es" | "en" | "unknown",
    "scraped_at": "2025-01-15T10:30:00",
    "processed_at": "2025-01-15T10:30:05"
}
```

---

## üéØ Mejores Pr√°cticas

1. **Usar delays apropiados**: M√≠nimo 3 segundos entre requests
2. **Validar datos extra√≠dos**: Siempre verificar que los datos sean correctos
3. **Manejar errores**: Usar try-except para manejar errores gracefully
4. **Logs detallados**: Usar logging para debugging
5. **Respetar ToS**: Solo scrapear contenido p√∫blico y respetar t√©rminos de servicio
6. **Rate limiting**: No hacer demasiados requests en poco tiempo

---

## üìù Notas Importantes

- ‚ö†Ô∏è **Solo para fines acad√©micos**: Este c√≥digo es para aprendizaje y educaci√≥n
- ‚ö†Ô∏è **Respeta los ToS**: Twitter y Facebook tienen pol√≠ticas estrictas sobre scraping
- ‚ö†Ô∏è **Autenticaci√≥n**: Mucho contenido requiere autenticaci√≥n para acceder
- ‚ö†Ô∏è **Selectores cambian**: Las plataformas actualizan su HTML frecuentemente
- ‚ö†Ô∏è **Rate limiting**: No abuses del sistema para evitar bloqueos

---

## üîÑ Actualizaciones Recientes

### v2.0 - Mejoras Principales

- ‚úÖ Expansi√≥n autom√°tica de contenido colapsado
- ‚úÖ Validaci√≥n de URLs de im√°genes
- ‚úÖ Parseo mejorado de m√©tricas (K, M, B)
- ‚úÖ Selectores CSS/XPath actualizados
- ‚úÖ An√°lisis de sentimiento con VADER/TextBlob
- ‚úÖ Categorizaci√≥n mejorada con keywords expandidas
- ‚úÖ Retry logic para elementos que fallan
- ‚úÖ Script de prueba para validaci√≥n

---

## üìû Soporte

Si encuentras problemas:
1. Revisa los logs para ver errores espec√≠ficos
2. Ejecuta el script de prueba: `python test_social_media_extraction.py`
3. Verifica que todas las dependencias est√©n instaladas
4. Revisa esta gu√≠a de troubleshooting

---

**¬°Happy Scraping! üöÄ**















