#!/usr/bin/env python3
"""
SCRAPER DE FACEBOOK - M√âTODO OFICIAL CON GRAPH API

Este m√©todo usa la API oficial de Facebook (m√°s confiable y legal)

IMPORTANTE: Este c√≥digo es solo para fines acad√©micos y educativos.
Respeta los t√©rminos de servicio de Facebook y las leyes locales.
"""

import requests
import json
import logging
from datetime import datetime
from typing import List, Dict, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FacebookGraphScraper:
    """
    Scraper de Facebook usando Graph API oficial
    """
    
    def __init__(self, access_token: Optional[str] = None):
        """
        Inicializar el scraper de Facebook Graph API
        
        Args:
            access_token: Token de acceso de Facebook (opcional, puede estar en env)
        """
        self.access_token = access_token or self._get_access_token_from_env()
        self.base_url = "https://graph.facebook.com/v18.0"
        
        if not self.access_token:
            logger.warning("‚ö†Ô∏è No se proporcion√≥ Access Token. El scraping puede fallar.")
            logger.info("üí° Para obtener un token: https://developers.facebook.com/apps/")
    
    def _get_access_token_from_env(self) -> Optional[str]:
        """Obtener access token de variables de entorno"""
        import os
        return os.getenv('FACEBOOK_ACCESS_TOKEN') or os.getenv('FB_ACCESS_TOKEN')
    
    def get_page_id(self, page_username: str) -> Optional[Dict]:
        """
        Obtiene el ID de la p√°gina desde su username
        
        Args:
            page_username: Nombre de usuario de la p√°gina (ej: 'elcomercio.pe')
        
        Returns:
            Diccionario con informaci√≥n de la p√°gina o None si hay error
        """
        if not self.access_token:
            logger.error("‚ùå No hay Access Token configurado")
            return None
        
        # Limpiar el username (remover https://, facebook.com, etc.)
        page_username = page_username.replace('https://', '').replace('http://', '')
        page_username = page_username.replace('www.facebook.com/', '').replace('facebook.com/', '')
        page_username = page_username.replace('fb.com/', '').replace('m.facebook.com/', '')
        page_username = page_username.strip('/')
        
        url = f"{self.base_url}/{page_username}"
        params = {
            'fields': 'id,name,followers_count,username',
            'access_token': self.access_token
        }
        
        try:
            logger.info(f"üîç Obteniendo informaci√≥n de la p√°gina: {page_username}")
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            page_data = response.json()
            
            logger.info(f"‚úÖ P√°gina encontrada: {page_data.get('name')} (ID: {page_data.get('id')})")
            return page_data
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 401:
                logger.error("‚ùå Access Token inv√°lido o expirado")
                logger.error("üí° Obt√©n un nuevo token en: https://developers.facebook.com/tools/explorer/")
            elif e.response.status_code == 404:
                logger.error(f"‚ùå P√°gina no encontrada: {page_username}")
                logger.error("üí° Verifica que el nombre de usuario sea correcto")
            else:
                logger.error(f"‚ùå Error HTTP obteniendo p√°gina: {e}")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Error obteniendo p√°gina: {e}")
            return None
    
    def get_posts(self, page_id: str, limit: int = 100) -> List[Dict]:
        """
        Extrae posts de una p√°gina de Facebook
        
        Args:
            page_id: ID de la p√°gina de Facebook
            limit: N√∫mero m√°ximo de posts a extraer
        
        Returns:
            Lista de diccionarios con datos de posts
        """
        if not self.access_token:
            logger.error("‚ùå No hay Access Token configurado")
            return []
        
        url = f"{self.base_url}/{page_id}/posts"
        
        params = {
            'fields': 'id,message,created_time,full_picture,permalink_url,shares,reactions.summary(true),comments.summary(true)',
            'limit': min(limit, 100),  # Facebook limita a 100 por request
            'access_token': self.access_token
        }
        
        all_posts = []
        
        try:
            logger.info(f"üì• Extrayendo hasta {limit} posts de la p√°gina {page_id}...")
            
            while len(all_posts) < limit:
                response = requests.get(url, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                if 'data' not in data or len(data['data']) == 0:
                    logger.info("‚ÑπÔ∏è No hay m√°s posts disponibles")
                    break
                
                for post in data['data']:
                    if len(all_posts) >= limit:
                        break
                    processed_post = self.process_post(post)
                    all_posts.append(processed_post)
                    logger.debug(f"‚úÖ Post extra√≠do: {processed_post.get('id')}")
                
                logger.info(f"üìä Extra√≠dos {len(all_posts)}/{limit} posts...")
                
                # Paginaci√≥n
                if 'paging' in data and 'next' in data['paging']:
                    url = data['paging']['next']
                    params = {}  # Los par√°metros ya est√°n en la URL next
                else:
                    break
            
            logger.info(f"‚úÖ Total de posts extra√≠dos: {len(all_posts)}")
            return all_posts
        
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 401:
                logger.error("‚ùå Access Token inv√°lido o expirado")
            elif e.response.status_code == 403:
                logger.error("‚ùå No tienes permisos para acceder a esta p√°gina")
                logger.error("üí° Necesitas permisos: pages_read_engagement, pages_show_list")
            else:
                logger.error(f"‚ùå Error HTTP extrayendo posts: {e}")
            return []
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Error extrayendo posts: {e}")
            return []
    
    def process_post(self, post: Dict) -> Dict:
        """
        Procesa y estructura los datos del post en el formato esperado
        
        Args:
            post: Diccionario con datos del post de Facebook Graph API
        
        Returns:
            Diccionario con datos procesados en formato est√°ndar
        """
        # Extraer m√©tricas
        reactions = post.get('reactions', {})
        reactions_summary = reactions.get('summary', {})
        likes = reactions_summary.get('total_count', 0)
        
        comments_data = post.get('comments', {})
        comments_summary = comments_data.get('summary', {})
        comments = comments_summary.get('total_count', 0)
        
        shares_data = post.get('shares', {})
        shares = shares_data.get('count', 0)
        
        # Extraer texto
        message = post.get('message', 'Sin texto')
        
        return {
            'id': post.get('id', ''),
            'platform': 'facebook',
            'username': 'P√°gina de Facebook',  # Se puede mejorar extrayendo el nombre de la p√°gina
            'text': message,
            'cleaned_text': message.strip(),
            'image_url': post.get('full_picture', None),
            'video_url': None,  # Los videos requieren campo adicional
            'url': post.get('permalink_url', ''),
            'date': post.get('created_time', datetime.now().isoformat()),
            'created_at': post.get('created_time', datetime.now().isoformat()),
            'likes': likes,
            'comments': comments,
            'shares': shares,
            'retweets': 0,  # Facebook no tiene retweets
            'replies': comments,  # Usar comments como replies
            'hashtags': self._extract_hashtags(message),
            'category': self.categorize_post(message),
            'sentiment': 'neutral',  # Se procesar√° despu√©s
            'detected_language': 'unknown',  # Se detectar√° despu√©s
            'scraped_at': datetime.now().isoformat()
        }
    
    def _extract_hashtags(self, text: str) -> List[str]:
        """Extraer hashtags del texto"""
        import re
        hashtags = re.findall(r'#\w+', text)
        return hashtags
    
    def categorize_post(self, text: str) -> str:
        """
        Categoriza el post por palabras clave
        
        Args:
            text: Texto del post
        
        Returns:
            Categor√≠a del post
        """
        if not text:
            return 'general'
        
        text_lower = text.lower()
        
        categorias = {
            'tecnolog√≠a': ['tecnolog√≠a', 'tech', 'digital', 'software', 'app', 'internet', 'cibern√©tico', 'innovaci√≥n'],
            'negocios': ['negocio', 'empresa', 'comercio', 'mercado', 'econom√≠a', 'venta', 'finanzas', 'empresarial'],
            'deportes': ['deporte', 'f√∫tbol', 'campeonato', 'equipo', 'partido', 'atleta', 'competencia'],
            'pol√≠tica': ['pol√≠tica', 'gobierno', 'elecci√≥n', 'presidente', 'congreso', 'democracia', 'elecci√≥n'],
            'entretenimiento': ['m√∫sica', 'cine', 'pel√≠cula', 'artista', 'show', 'concierto', 'espect√°culo'],
            'salud': ['salud', 'm√©dico', 'hospital', 'enfermedad', 'tratamiento', 'cuidado'],
            'educaci√≥n': ['educaci√≥n', 'escuela', 'universidad', 'estudiante', 'aprendizaje', 'acad√©mico']
        }
        
        for categoria, palabras in categorias.items():
            if any(palabra in text_lower for palabra in palabras):
                return categoria
        
        return 'general'
    
    def scrape_from_url(self, url: str, max_posts: int = 50) -> List[Dict]:
        """
        Scraping desde una URL de Facebook usando Graph API
        
        Args:
            url: URL de Facebook (p√°gina, perfil, post)
            max_posts: M√°ximo de posts a extraer
        
        Returns:
            Lista de diccionarios con datos de posts
        """
        if not self.access_token:
            logger.error("‚ùå No hay Access Token configurado para Graph API")
            logger.error("üí° Configura el token en variables de entorno o pasa el par√°metro")
            return []
        
        # Extraer username de la URL
        page_username = url.replace('https://', '').replace('http://', '')
        page_username = page_username.replace('www.facebook.com/', '').replace('facebook.com/', '')
        page_username = page_username.replace('fb.com/', '').replace('m.facebook.com/', '')
        page_username = page_username.strip('/')
        
        # Si la URL tiene /posts/ o /photos/, extraer el username de antes
        if '/' in page_username:
            page_username = page_username.split('/')[0]
        
        logger.info(f"üîç Scrapeando Facebook con Graph API: {page_username}")
        
        # Obtener informaci√≥n de la p√°gina
        page_info = self.get_page_id(page_username)
        
        if not page_info:
            logger.error("‚ùå No se pudo obtener la informaci√≥n de la p√°gina")
            return []
        
        # Extraer posts
        page_id = page_info['id']
        posts = self.get_posts(page_id, limit=max_posts)
        
        if posts:
            logger.info(f"‚úÖ ‚úÖ ‚úÖ GRAPH API EXITOSO: {len(posts)} posts REALES extra√≠dos")
            return posts
        else:
            logger.warning("‚ö†Ô∏è No se pudieron extraer posts")
            return []


# ====================== FUNCI√ìN DE CONVENIENCIA ======================

def create_graph_scraper(access_token: Optional[str] = None) -> Optional[FacebookGraphScraper]:
    """
    Crear instancia del scraper Graph API
    
    Args:
        access_token: Token de acceso (opcional, se puede obtener de env)
    
    Returns:
        Instancia del scraper o None si no hay token
    """
    scraper = FacebookGraphScraper(access_token)
    
    if not scraper.access_token:
        logger.warning("‚ö†Ô∏è No se proporcion√≥ Access Token")
        logger.info("üí° Para usar Graph API:")
        logger.info("   1. Obt√©n un token en: https://developers.facebook.com/tools/explorer/")
        logger.info("   2. Configura FACEBOOK_ACCESS_TOKEN en variables de entorno")
        logger.info("   3. O pasa el token al crear el scraper")
        return None
    
    return scraper















