#!/usr/bin/env python3
"""
Script de Prueba para Validar Extracci√≥n de Redes Sociales
Valida que el sistema extraiga correctamente:
- Contenido completo sin truncar
- URLs de im√°genes v√°lidas (no null)
- M√©tricas num√©ricas correctas
- Categor√≠a relevante
- Sentimiento preciso
"""

import json
import logging
from social_media_scraper import TwitterScraper, FacebookScraper
from social_media_processor import SocialMediaProcessor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def validate_post_data(post: dict, platform: str) -> dict:
    """
    Validar que un post tenga todos los datos necesarios
    
    Args:
        post: Diccionario con datos del post
        platform: 'twitter' o 'facebook'
    
    Returns:
        Diccionario con resultados de validaci√≥n
    """
    results = {
        'valid': True,
        'errors': [],
        'warnings': []
    }
    
    # Validar texto
    text = post.get('text', '')
    if not text or len(text.strip()) < 10:
        results['valid'] = False
        results['errors'].append('Texto muy corto o vac√≠o (< 10 caracteres)')
    elif len(text) < 30:
        results['warnings'].append(f'Texto corto ({len(text)} caracteres), puede estar truncado')
    
    # Validar username
    username = post.get('username', '')
    if not username or username == 'unknown':
        results['warnings'].append('Username no encontrado o gen√©rico')
    
    # Validar imagen
    image_url = post.get('image_url')
    if not image_url:
        results['warnings'].append('No se encontr√≥ imagen (image_url: null)')
    elif not isinstance(image_url, str) or not image_url.startswith('http'):
        results['errors'].append(f'URL de imagen inv√°lida: {image_url}')
        results['valid'] = False
    
    # Validar m√©tricas
    if platform == 'twitter':
        likes = post.get('likes', 0)
        retweets = post.get('retweets', 0)
        replies = post.get('replies', 0)
        
        if not isinstance(likes, int) or likes < 0:
            results['warnings'].append(f'Likes inv√°lido: {likes}')
        if not isinstance(retweets, int) or retweets < 0:
            results['warnings'].append(f'Retweets inv√°lido: {retweets}')
        if not isinstance(replies, int) or replies < 0:
            results['warnings'].append(f'Replies inv√°lido: {replies}')
    
    elif platform == 'facebook':
        likes = post.get('likes', 0)
        comments = post.get('comments', 0)
        shares = post.get('shares', 0)
        
        if not isinstance(likes, int) or likes < 0:
            results['warnings'].append(f'Likes inv√°lido: {likes}')
        if not isinstance(comments, int) or comments < 0:
            results['warnings'].append(f'Comments inv√°lido: {comments}')
        if not isinstance(shares, int) or shares < 0:
            results['warnings'].append(f'Shares inv√°lido: {shares}')
    
    # Validar fecha
    date = post.get('date', '')
    if not date:
        results['warnings'].append('Fecha no encontrada')
    
    # Validar URL
    url = post.get('url', '')
    if not url:
        results['warnings'].append('URL del post no encontrada')
    elif not url.startswith('http'):
        results['warnings'].append(f'URL inv√°lida: {url}')
    
    return results

def test_twitter_extraction():
    """Probar extracci√≥n de Twitter"""
    print("\n" + "="*60)
    print("üê¶ PRUEBA DE EXTRACCI√ìN DE TWITTER/X")
    print("="*60)
    
    try:
        scraper = TwitterScraper(headless=True, delay=3)
        
        # Probar con una URL de b√∫squeda
        test_url = "https://twitter.com/search?q=tecnologia&src=typed_query&f=live"
        print(f"\nüîç Scrapeando desde: {test_url}")
        
        posts = scraper.scrape_from_url(test_url, max_tweets=10)
        
        print(f"\n‚úÖ Posts extra√≠dos: {len(posts)}")
        
        if len(posts) == 0:
            print("‚ö†Ô∏è No se extrajeron posts. Puede requerir autenticaci√≥n.")
            return
        
        processor = SocialMediaProcessor()
        valid_posts = 0
        
        for i, post in enumerate(posts[:10], 1):
            print(f"\n{'='*60}")
            print(f"üì± POST {i}/{len(posts)}")
            print(f"{'='*60}")
            
            # Validar datos
            validation = validate_post_data(post, 'twitter')
            
            # Procesar post
            processed = processor.process_tweet(post)
            
            # Mostrar datos
            print(f"‚úÖ Usuario: {processed.get('username', 'N/A')}")
            print(f"üìù Texto ({len(processed.get('text', ''))} chars): {processed.get('text', '')[:100]}...")
            print(f"üñºÔ∏è Imagen: {'‚úÖ' if processed.get('image_url') else '‚ùå'} {processed.get('image_url', 'N/A')[:60] if processed.get('image_url') else 'N/A'}...")
            print(f"üëç Likes: {processed.get('likes', 0)}")
            print(f"üîÑ Retweets: {processed.get('retweets', 0)}")
            print(f"üí¨ Replies: {processed.get('replies', 0)}")
            print(f"üè∑Ô∏è Categor√≠a: {processed.get('category', 'N/A')}")
            print(f"üòä Sentimiento: {processed.get('sentiment', 'N/A')}")
            
            # Mostrar validaci√≥n
            if validation['valid']:
                print("‚úÖ VALIDACI√ìN: Post v√°lido")
                valid_posts += 1
            else:
                print("‚ùå VALIDACI√ìN: Post inv√°lido")
            
            if validation['errors']:
                for error in validation['errors']:
                    print(f"   ‚ùå Error: {error}")
            
            if validation['warnings']:
                for warning in validation['warnings']:
                    print(f"   ‚ö†Ô∏è Advertencia: {warning}")
        
        print(f"\n{'='*60}")
        print(f"üìä RESUMEN: {valid_posts}/{len(posts)} posts v√°lidos")
        print(f"{'='*60}")
        
        scraper.close()
        
    except Exception as e:
        print(f"‚ùå Error en prueba de Twitter: {e}")
        import traceback
        traceback.print_exc()

def test_facebook_extraction():
    """Probar extracci√≥n de Facebook"""
    print("\n" + "="*60)
    print("üìò PRUEBA DE EXTRACCI√ìN DE FACEBOOK")
    print("="*60)
    
    try:
        scraper = FacebookScraper(headless=True, delay=3)
        
        # Probar con una p√°gina p√∫blica (ejemplo)
        test_url = "https://www.facebook.com/facebook"
        print(f"\nüîç Scrapeando desde: {test_url}")
        
        posts = scraper.scrape_from_url(test_url, max_posts=10)
        
        print(f"\n‚úÖ Posts extra√≠dos: {len(posts)}")
        
        if len(posts) == 0:
            print("‚ö†Ô∏è No se extrajeron posts. Puede requerir autenticaci√≥n.")
            return
        
        processor = SocialMediaProcessor()
        valid_posts = 0
        
        for i, post in enumerate(posts[:10], 1):
            print(f"\n{'='*60}")
            print(f"üì± POST {i}/{len(posts)}")
            print(f"{'='*60}")
            
            # Validar datos
            validation = validate_post_data(post, 'facebook')
            
            # Procesar post
            processed = processor.process_tweet(post)
            
            # Mostrar datos
            print(f"‚úÖ Autor: {processed.get('username', 'N/A')}")
            print(f"üìù Texto ({len(processed.get('text', ''))} chars): {processed.get('text', '')[:100]}...")
            print(f"üñºÔ∏è Imagen: {'‚úÖ' if processed.get('image_url') else '‚ùå'} {processed.get('image_url', 'N/A')[:60] if processed.get('image_url') else 'N/A'}...")
            print(f"üé• Video: {'‚úÖ' if processed.get('video_url') else '‚ùå'}")
            print(f"üëç Likes: {processed.get('likes', 0)}")
            print(f"üí¨ Comments: {processed.get('comments', 0)}")
            print(f"üì§ Shares: {processed.get('shares', 0)}")
            print(f"üè∑Ô∏è Categor√≠a: {processed.get('category', 'N/A')}")
            print(f"üòä Sentimiento: {processed.get('sentiment', 'N/A')}")
            
            # Mostrar validaci√≥n
            if validation['valid']:
                print("‚úÖ VALIDACI√ìN: Post v√°lido")
                valid_posts += 1
            else:
                print("‚ùå VALIDACI√ìN: Post inv√°lido")
            
            if validation['errors']:
                for error in validation['errors']:
                    print(f"   ‚ùå Error: {error}")
            
            if validation['warnings']:
                for warning in validation['warnings']:
                    print(f"   ‚ö†Ô∏è Advertencia: {warning}")
        
        print(f"\n{'='*60}")
        print(f"üìä RESUMEN: {valid_posts}/{len(posts)} posts v√°lidos")
        print(f"{'='*60}")
        
        scraper.close()
        
    except Exception as e:
        print(f"‚ùå Error en prueba de Facebook: {e}")
        import traceback
        traceback.print_exc()

def test_metric_parsing():
    """Probar parseo de m√©tricas"""
    print("\n" + "="*60)
    print("üî¢ PRUEBA DE PARSEO DE M√âTRICAS")
    print("="*60)
    
    scraper = TwitterScraper(headless=True, delay=1)
    
    test_cases = [
        ("1.2K", 1200),
        ("5K", 5000),
        ("1.5M", 1500000),
        ("2M", 2000000),
        ("500", 500),
        ("1.2B", 1200000000),
        ("", 0),
        ("abc", 0),
    ]
    
    print("\nüìä Resultados:")
    all_passed = True
    for input_str, expected in test_cases:
        result = scraper._parse_metric(input_str)
        status = "‚úÖ" if result == expected else "‚ùå"
        print(f"{status} '{input_str}' -> {result} (esperado: {expected})")
        if result != expected:
            all_passed = False
    
    if all_passed:
        print("\n‚úÖ Todas las pruebas de parseo pasaron")
    else:
        print("\n‚ùå Algunas pruebas de parseo fallaron")
    
    scraper.close()

if __name__ == "__main__":
    print("="*60)
    print("üß™ TESTING DE EXTRACCI√ìN DE REDES SOCIALES")
    print("="*60)
    
    # Probar parseo de m√©tricas
    test_metric_parsing()
    
    # Probar extracci√≥n de Twitter
    test_twitter_extraction()
    
    # Probar extracci√≥n de Facebook
    test_facebook_extraction()
    
    print("\n" + "="*60)
    print("‚úÖ TESTING COMPLETADO")
    print("="*60)















